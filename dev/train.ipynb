{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-07T06:30:47.682346Z",
     "iopub.status.busy": "2020-12-07T06:30:47.682346Z",
     "iopub.status.idle": "2020-12-07T06:30:48.954032Z",
     "shell.execute_reply": "2020-12-07T06:30:48.954032Z",
     "shell.execute_reply.started": "2020-12-07T06:30:47.682346Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm as tq\n",
    "import tqdm.notebook as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-07T06:31:06.897780Z",
     "iopub.status.busy": "2020-12-07T06:31:06.897780Z",
     "iopub.status.idle": "2020-12-07T06:31:06.901798Z",
     "shell.execute_reply": "2020-12-07T06:31:06.901798Z",
     "shell.execute_reply.started": "2020-12-07T06:31:06.897780Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.optim import lr_scheduler\n",
    "from torch.optim.lr_scheduler import _LRScheduler, CosineAnnealingLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-07T06:49:36.956869Z",
     "iopub.status.busy": "2020-12-07T06:49:36.955873Z",
     "iopub.status.idle": "2020-12-07T06:49:36.993770Z",
     "shell.execute_reply": "2020-12-07T06:49:36.993770Z",
     "shell.execute_reply.started": "2020-12-07T06:49:36.956869Z"
    }
   },
   "outputs": [],
   "source": [
    "from bnet.learner import Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-07T06:31:14.194590Z",
     "iopub.status.busy": "2020-12-07T06:31:14.194590Z",
     "iopub.status.idle": "2020-12-07T06:31:14.201572Z",
     "shell.execute_reply": "2020-12-07T06:31:14.201572Z",
     "shell.execute_reply.started": "2020-12-07T06:31:14.194590Z"
    }
   },
   "outputs": [],
   "source": [
    "class DelayerScheduler(_LRScheduler):\n",
    "    \"\"\"\n",
    "    CREDIT: https://github.com/pabloppp/pytorch-tools\n",
    "    Start with a flat lr schedule until it reaches N epochs then applies a scheduler\n",
    "    \"\"\"\n",
    "    def __init__(self, optimizer, delay_epochs, after_scheduler):\n",
    "        self.delay_epochs = delay_epochs\n",
    "        self.after_scheduler = after_scheduler\n",
    "        self.finished = False\n",
    "        super().__init__(optimizer)\n",
    "        \n",
    "    def get_lr(self):\n",
    "        if self.last_epoch >= self.delay_epochs:\n",
    "            if not self.finished:\n",
    "                self.after_scheduler.base_lrs = self.base_lrs\n",
    "                self.finished = True\n",
    "            return self.after_scheduler.get_last_lr()\n",
    "        \n",
    "        return self.base_lrs\n",
    "    \n",
    "    def step(self, epoch=None):\n",
    "        if self.finished:\n",
    "            if epoch is None: \n",
    "                self.after_scheduler.step(None)\n",
    "            else:\n",
    "                self.after_scheduler.step(epoch - self.delay_epochs)\n",
    "        else:\n",
    "            return super(DelayerScheduler, self).step(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-07T06:31:17.846923Z",
     "iopub.status.busy": "2020-12-07T06:31:17.846923Z",
     "iopub.status.idle": "2020-12-07T06:31:17.850913Z",
     "shell.execute_reply": "2020-12-07T06:31:17.850913Z",
     "shell.execute_reply.started": "2020-12-07T06:31:17.846923Z"
    }
   },
   "outputs": [],
   "source": [
    "def FlatCosAnnealScheduler(optimizer, delay_epochs, cosine_annealing_epochs):\n",
    "    base_scheduler = CosineAnnealingLR(optimizer, cosine_annealing_epochs)\n",
    "    return DelayerScheduler(optimizer, delay_epochs, base_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-07T06:31:21.939396Z",
     "iopub.status.busy": "2020-12-07T06:31:21.939396Z",
     "iopub.status.idle": "2020-12-07T06:31:21.943386Z",
     "shell.execute_reply": "2020-12-07T06:31:21.943386Z",
     "shell.execute_reply.started": "2020-12-07T06:31:21.939396Z"
    }
   },
   "outputs": [],
   "source": [
    "def delayer(epochs, pct_start=0.8): return int(epochs * pct_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-07T06:31:41.385238Z",
     "iopub.status.busy": "2020-12-07T06:31:41.385238Z",
     "iopub.status.idle": "2020-12-07T06:31:41.401232Z",
     "shell.execute_reply": "2020-12-07T06:31:41.401232Z",
     "shell.execute_reply.started": "2020-12-07T06:31:41.385238Z"
    }
   },
   "outputs": [],
   "source": [
    "class Evaluate:\n",
    "    \"\"\"\n",
    "    Keeping track of stats when training a model. Evolution will be all training stats for the entire training while summary is epoch summary per epoch\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.evolution = {'train_loss':[], 'train_acc':[], 'valid_loss':[], 'valid_acc':[]}\n",
    "        self.summary = {'train_loss_summary':[], 'train_acc_summary':[], 'valid_loss_summary':[], 'valid_acc_summary':[]}\n",
    "        self.best_stats = {}\n",
    "        \n",
    "    def update_summary(self, train_loss, train_acc, valid_loss, valid_acc):\n",
    "        \"\"\"Call after each epoch\"\"\"\n",
    "        self.summary['train_loss_summary'].append(train_loss)\n",
    "        self.summary['train_acc_summary'].append(train_acc)\n",
    "        self.summary['valid_loss_summary'].append(valid_loss)\n",
    "        self.summary['valid_acc_summary'].append(valid_acc)\n",
    "    \n",
    "    def update_evolution(self, ds_type, loss, acc):\n",
    "        \"\"\"Call after each batch\"\"\"\n",
    "        if ds_type=='train':\n",
    "            self.evolution['train_loss'].append(loss)\n",
    "            self.evolution['train_acc'].append(acc)\n",
    "        elif ds_type=='valid':\n",
    "            self.evolution['valid_loss'].append(loss)\n",
    "            self.evolution['valid_acc'].append(acc)\n",
    "        else: return\n",
    "        \n",
    "    def update_best_stats(self, iteration, train_loss, train_acc, valid_loss, valid_acc):\n",
    "        self.best_stats['iteration'] = iteration\n",
    "        self.best_stats['train_loss'] = train_loss\n",
    "        self.best_stats['train_acc'] = train_acc\n",
    "        self.best_stats['valid_losss'] = valid_loss\n",
    "        self.best_stats['valid_acc'] = valid_acc\n",
    "        \n",
    "    def report(self):\n",
    "        tq.write(f\"\"\"Train loss: {self.summary['train_loss_summary'][-1]:0f}, Train acc: {self.summary['train_acc_summary'][-1]:0f}, Valid loss: {self.summary['valid_loss_summary'][-1]:0f}, Valid acc: {self.summary['valid_acc_summary'][-1]:0f}\"\"\")\n",
    "        \n",
    "    def summarize(self): self.summary = pd.DataFrame(self.summary)\n",
    "    \n",
    "    def report_best(self):\n",
    "        print(f\"\"\"\n",
    "        Best Model Stats:\n",
    "        ---------------------------------\n",
    "        Iteration  : {self.best_stats['iteration']}\n",
    "        Train Loss : {self.best_stats['train_loss']}\n",
    "        Train Acc  : {self.best_stats['train_acc']}\n",
    "        Valid Loss : {self.best_stats['valid_loss']}\n",
    "        Valid Acc  : {self.best_stats['valid_acc']}\n",
    "        \"\"\")\n",
    "        \n",
    "    def plot_summary(self):\n",
    "        if isinstance(self.summary, pd.DataFrame): self.summary.plot()\n",
    "            \n",
    "    def plot_evolution(self):\n",
    "        fig, axs = plt.subplots(2,2, figsize=(15,10))\n",
    "        \n",
    "        axs[0,0].plot(self.evolution['train_acc'])\n",
    "        axs[0,0].set_xlabel('Iterations')\n",
    "        axs[0,0].set_ylabel('Accuracy')\n",
    "        axs[0,0].set_title('Train Accuracy')\n",
    "        \n",
    "        axs[0,1].plot(self.evolution['valid_acc'])\n",
    "        axs[0,1].set_xlabel('Iterations')\n",
    "        axs[0,1].set_ylabel('Accuracy')\n",
    "        axs[0,1].set_title('Valid Accuracy')\n",
    "        \n",
    "        axs[1,0].plot(self.evolution['train_loss'])\n",
    "        axs[1,0].set_xlabel('Iterations')\n",
    "        axs[1,0].set_ylabel('Loss')\n",
    "        axs[1,0].set_title('Train Loss')\n",
    "        \n",
    "        axs[1,1].plot(self.evolution['valid_loss'])\n",
    "        axs[1,1].set_xlabel('Iterations')\n",
    "        axs[1,1].set_ylabel('Loss')\n",
    "        axs[1,1].set_title('Valid Loss')\n",
    "        \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-07T06:31:50.537995Z",
     "iopub.status.busy": "2020-12-07T06:31:50.537995Z",
     "iopub.status.idle": "2020-12-07T06:31:50.541983Z",
     "shell.execute_reply": "2020-12-07T06:31:50.541983Z",
     "shell.execute_reply.started": "2020-12-07T06:31:50.537995Z"
    }
   },
   "outputs": [],
   "source": [
    "def metrics_batch(output, target, metric_fn=None):\n",
    "    if metric_fn: return metric_fn(output, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-07T06:32:05.851562Z",
     "iopub.status.busy": "2020-12-07T06:32:05.851562Z",
     "iopub.status.idle": "2020-12-07T06:32:05.856549Z",
     "shell.execute_reply": "2020-12-07T06:32:05.856549Z",
     "shell.execute_reply.started": "2020-12-07T06:32:05.851562Z"
    }
   },
   "outputs": [],
   "source": [
    "def loss_batch(loss_fn, output, target, metric_fn=None, opt_fn=None, scheduler=None):\n",
    "    \"\"\"\n",
    "    Calculate loss and metric for batch\n",
    "    \"\"\"\n",
    "    loss = loss_fn(output, target)\n",
    "    metric = metrics_batch(output, target, metric_fn)\n",
    "    \n",
    "    if opt_fn:\n",
    "        opt_fn.zero_grad()\n",
    "        loss.backward()\n",
    "        opt_fn.step()\n",
    "        if scheduler: scheduler.step()\n",
    "            \n",
    "    return loss.data.cpu().item(), metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-07T06:48:50.533800Z",
     "iopub.status.busy": "2020-12-07T06:48:50.533800Z",
     "iopub.status.idle": "2020-12-07T06:48:50.540813Z",
     "shell.execute_reply": "2020-12-07T06:48:50.540813Z",
     "shell.execute_reply.started": "2020-12-07T06:48:50.533800Z"
    }
   },
   "outputs": [],
   "source": [
    "def loss_epoch(model, dataloader, ds_type, evaluator, loss_fn, metric_fn=None, opt_fn=None, scheduler=None, device=None, inner_bar=None, inner_loop=None):\n",
    "    \"\"\"\n",
    "    Calculates loss per batch\n",
    "    \"\"\"\n",
    "    running_loss, running_metric = 0,0\n",
    "    n = len(dataloader)\n",
    "    nb_ = 0\n",
    "    device = torch.device('cpu') if device is None else device\n",
    "    \n",
    "    for i,(xb,yb) in enumerate(dataloader):\n",
    "        inner_bar.update(1)\n",
    "        nb = yb.size(0)\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "        output = model(xb)\n",
    "        \n",
    "        loss_b, metric_b = loss_batch(loss_fn, output, yb, metric_fn, opt_fn, scheduler)\n",
    "        running_loss+=loss_b\n",
    "        running_metric+=metric_b\n",
    "        nb_+=nb\n",
    "        \n",
    "        evaluator.update_evolution(ds_type, running_loss/float(i), running_metric/float(nb_))\n",
    "        \n",
    "    metric_e = running_metric/float(nb_)\n",
    "    loss_e = running_loss/float(n)\n",
    "    return metric_e, loss_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-07T06:49:04.341364Z",
     "iopub.status.busy": "2020-12-07T06:49:04.340366Z",
     "iopub.status.idle": "2020-12-07T06:49:04.351370Z",
     "shell.execute_reply": "2020-12-07T06:49:04.351370Z",
     "shell.execute_reply.started": "2020-12-07T06:49:04.341364Z"
    }
   },
   "outputs": [],
   "source": [
    "def fit(learn, epochs=10, device=None, keep_best_state=True, **kwargs):\n",
    "    \"\"\"\n",
    "    train model with one cycle policy\n",
    "    \"\"\"\n",
    "    evaluator = Evaluate()\n",
    "    \n",
    "    # update opt\n",
    "    opt_fn = learn.opt_fn\n",
    "    \n",
    "    # base\n",
    "    loss_fn = learn.loss_fn\n",
    "    train_dl = learn.data.train_dl\n",
    "    valid_dl = learn.data.valid_dl\n",
    "    metric_fn = learn.metric_fn\n",
    "    device = learn.device if device is None else torch.device(device)\n",
    "    model = learn.model.to(device)\n",
    "    \n",
    "    # display settings\n",
    "    outter_bar = tqdm.tqdm(range(epochs))\n",
    "    outter_loop = range(epochs)\n",
    "    train_n = len(train_dl)\n",
    "    train_inner_bar = tqdm.tqdm(range(train_n), leave=False)\n",
    "    train_inner_loop = range(train_n)\n",
    "    valid_n = len(valid_dl)\n",
    "    valid_inner_bar = tqdm.tqdm(range(valid_n), leave=False)\n",
    "    valid_inner_loop = range(valid_n)\n",
    "    \n",
    "    # best model weights\n",
    "    if keep_best_state:\n",
    "        best_model_wts = deepcopy(model.state_dict())\n",
    "        best_loss = float('inf')\n",
    "        \n",
    "    # Training\n",
    "    for epoch in outter_loop:\n",
    "        train_inner_bar.reset()\n",
    "        valid_inner_bar.reset()\n",
    "        \n",
    "        # train\n",
    "        model.train()\n",
    "        train_metric, train_loss = loss_epoch(model, train_dl, 'train', evaluator, loss_fn, metric_fn, opt_fn, None, device, train_inner_bar, train_inner_loop)\n",
    "        \n",
    "        # eval\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            valid_metric, valid_loss = loss_epoch(model, valid_dl, 'valid', evaluator, loss_fn, metric_fn, device=device, inner_bar=valid_inner_bar, inner_loop=valid_inner_loop)\n",
    "            \n",
    "        # update evaluator\n",
    "        evaluator.update_summary(train_loss, train_metric, valid_loss, valid_metric)\n",
    "        \n",
    "        # keeping best\n",
    "        if keep_best_state:\n",
    "            if valid_loss<best_loss:\n",
    "                best_loss = valid_loss\n",
    "                best_model_wts = deepcopy(model.state_dict())\n",
    "                evaluator.update_best_stats(epoch+1, train_loss, train_metric, valid_loss, valid_metric)\n",
    "                \n",
    "        # report\n",
    "        outter_bar.update(1)\n",
    "        evaluator.report()\n",
    "        \n",
    "    # summurize training\n",
    "    evaluator.summarize()\n",
    "    learn.evaluator = evaluator\n",
    "    \n",
    "    # keep best weights\n",
    "    if keep_best_state: learn.model.load_state_dict(best_model_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-07T06:49:09.700353Z",
     "iopub.status.busy": "2020-12-07T06:49:09.700353Z",
     "iopub.status.idle": "2020-12-07T06:49:09.712320Z",
     "shell.execute_reply": "2020-12-07T06:49:09.712320Z",
     "shell.execute_reply.started": "2020-12-07T06:49:09.700353Z"
    }
   },
   "outputs": [],
   "source": [
    "def fit_one_cycle(learn, epochs=10, pct_start=0.8, div_factor=10., moms=(0.85, 0.95), device=None, keep_best_state=True, **kwargs):\n",
    "    \"\"\"\n",
    "    train model with one cycle policy\n",
    "    \"\"\"\n",
    "    # setting training params\n",
    "    evaluator = Evaluate()\n",
    "    \n",
    "    # scheduler params\n",
    "    steps_per_epoch = len(learn.data.train_dl)\n",
    "    b1, b2 = moms\n",
    "    opt_fn = learn.opt_fn\n",
    "    scheduler = lr_scheduler.OneCycleLR(opt_fn, max_lr=max_lr, steps_per_epoch=steps_per_epoch, epochs=epochs, pct_start=pct_start, div_factor=div_factor, base_momentum=b1, max_momentum=b2)\n",
    "    \n",
    "    # base\n",
    "    loss_fn = learn.loss_fn\n",
    "    train_dl = learn.data.train_dl\n",
    "    valid_dl = learn.data.valid_dl\n",
    "    metric_fn = learn.metric_fn\n",
    "    device = learn.device if device is None else torch.device(device)\n",
    "    model = learn.model.to(device)\n",
    "    \n",
    "    # display settings\n",
    "    outter_bar = tqdm.tqdm(range(epochs))\n",
    "    outter_loop = range(epochs)\n",
    "    train_n = len(train_dl)\n",
    "    train_inner_bar = tqdm.tqdm(range(train_n), leave=False)\n",
    "    train_inner_loop = range(train_n)\n",
    "    valid_n = len(valid_dl)\n",
    "    valid_inner_bar = tqdm.tqdm(range(valid_n), leave=False)\n",
    "    valid_inner_loop = range(valid_n)\n",
    "    \n",
    "    # best model weights\n",
    "    if keep_best_state:\n",
    "        best_model_wts = deepcopy(model.state_dict())\n",
    "        best_loss = float('inf')\n",
    "        \n",
    "    # Training\n",
    "    for epoch in outter_loop:\n",
    "        train_inner_bar.reset()\n",
    "        valid_inner_bar.reset()\n",
    "        \n",
    "        # train\n",
    "        model.train()\n",
    "        train_metric, train_loss = loss_epoch(model, train_dl, 'train', evaluator, loss_fn, metric_fn, opt_fn, scheduler, device, train_inner_bar, train_inner_loop)\n",
    "        \n",
    "        # eval\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            valid_metric, valid_loss = loss_epoch(model, valid_dl, 'valid', evaluator, loss_fn, metric_fn, device=device, inner_bar=valid_inner_bar, inner_loop=valid_inner_loop)\n",
    "            \n",
    "        # update evaluator\n",
    "        evaluator.update_summary(train_loss, train_metric, valid_loss, valid_metric)\n",
    "        \n",
    "        # keeping best\n",
    "        if keep_best_state:\n",
    "            if valid_loss<best_loss:\n",
    "                best_loss = valid_loss\n",
    "                best_model_wts = deepcopy(model.state_dict())\n",
    "                evaluator.update_best_stats(epoch+1, train_loss, train_metric, valid_loss, valid_metric)\n",
    "                \n",
    "        # report\n",
    "        outter_bar.update(1)\n",
    "        evaluator.report()\n",
    "        \n",
    "    # summurize training\n",
    "    evaluator.summarize()\n",
    "    learn.evaluator = evaluator\n",
    "    \n",
    "    # keep best weights\n",
    "    if keep_best_state: learn.model.load_state_dict(best_model_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-07T06:49:17.500538Z",
     "iopub.status.busy": "2020-12-07T06:49:17.500538Z",
     "iopub.status.idle": "2020-12-07T06:49:17.511537Z",
     "shell.execute_reply": "2020-12-07T06:49:17.511537Z",
     "shell.execute_reply.started": "2020-12-07T06:49:17.500538Z"
    }
   },
   "outputs": [],
   "source": [
    "def fit_flat_anneal(learn, epochs=10, pct_start=0.8, div_factor=10., moms=(0.85, 0.95), device=None, keep_best_state=True, **kwargs):\n",
    "    \"\"\"\n",
    "    train model with one cycle policy\n",
    "    \"\"\"\n",
    "    evaluator = Evaluate()\n",
    "    \n",
    "    # scheduler params\n",
    "    steps_per_epoch = len(learn.data.train_dl)\n",
    "    b1, b2 = moms\n",
    "    delay_epochs = delayer(epochs, pct_start)\n",
    "    opt_fn = learn.opt_fn\n",
    "    base_scheduler = CosineAnnealingLR(opt_fn, delay_epochs)\n",
    "    delayed_scheduler = DelayerScheduler(opt_fn, epochs-delay_epochs, base_scheduler)\n",
    "    \n",
    "    # base\n",
    "    loss_fn = learn.loss_fn\n",
    "    train_dl = learn.data.train_dl\n",
    "    valid_dl = learn.data.valid_dl\n",
    "    metric_fn = learn.metric_fn\n",
    "    device = learn.device if device is None else torch.device(device)\n",
    "    model = learn.model.to(device)\n",
    "    \n",
    "    # display settings\n",
    "    outter_bar = tqdm.tqdm(range(epochs))\n",
    "    outter_loop = range(epochs)\n",
    "    train_n = len(train_dl)\n",
    "    train_inner_bar = tqdm.tqdm(range(train_n), leave=False)\n",
    "    train_inner_loop = range(train_n)\n",
    "    valid_n = len(valid_dl)\n",
    "    valid_inner_bar = tqdm.tqdm(range(valid_n), leave=False)\n",
    "    valid_inner_loop = range(valid_n)\n",
    "    \n",
    "    # best model weights\n",
    "    if keep_best_state:\n",
    "        best_model_wts = deepcopy(model.state_dict())\n",
    "        best_loss = float('inf')\n",
    "        \n",
    "    # Training\n",
    "    for epoch in outter_loop:\n",
    "        train_inner_bar.reset()\n",
    "        valid_inner_bar.reset()\n",
    "        \n",
    "        # train\n",
    "        model.train()\n",
    "        train_metric, train_loss = loss_epoch(model, train_dl, 'train', evaluator, loss_fn, metric_fn, opt_fn, None, device, train_inner_bar, train_inner_loop)\n",
    "        \n",
    "        # eval\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            valid_metric, valid_loss = loss_epoch(model, valid_dl, 'valid', evaluator, loss_fn, metric_fn, device=device, inner_bar=valid_inner_bar, inner_loop=valid_inner_loop)\n",
    "            \n",
    "        # update evaluator\n",
    "        evaluator.update_summary(train_loss, train_metric, valid_loss, valid_metric)\n",
    "        \n",
    "        # keeping best\n",
    "        if keep_best_state:\n",
    "            if valid_loss<best_loss:\n",
    "                best_loss = valid_loss\n",
    "                best_model_wts = deepcopy(model.state_dict())\n",
    "                evaluator.update_best_stats(epoch+1, train_loss, train_metric, valid_loss, valid_metric)\n",
    "                \n",
    "        # update scheduler\n",
    "        delayed_scheduler.step()\n",
    "        \n",
    "        # report\n",
    "        outter_bar.update(1)\n",
    "        evaluator.report()\n",
    "        \n",
    "    # summurize training\n",
    "    evaluator.summarize()\n",
    "    learn.evaluator = evaluator\n",
    "    \n",
    "    # keep best weights\n",
    "    if keep_best_state: learn.model.load_state_dict(best_model_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-07T06:49:41.973700Z",
     "iopub.status.busy": "2020-12-07T06:49:41.973700Z",
     "iopub.status.idle": "2020-12-07T06:49:41.976692Z",
     "shell.execute_reply": "2020-12-07T06:49:41.976692Z",
     "shell.execute_reply.started": "2020-12-07T06:49:41.973700Z"
    }
   },
   "outputs": [],
   "source": [
    "Learner.fit = fit\n",
    "Learner.fit_one_cycle = fit_one_cycle\n",
    "Learner.fit_flat_anneal = fit_flat_anneal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
