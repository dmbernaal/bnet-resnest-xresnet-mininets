{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T22:53:38.975921Z",
     "iopub.status.busy": "2020-12-06T22:53:38.975921Z",
     "iopub.status.idle": "2020-12-06T22:53:38.979911Z",
     "shell.execute_reply": "2020-12-06T22:53:38.979911Z",
     "shell.execute_reply.started": "2020-12-06T22:53:38.975921Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.modules.utils import _pair\n",
    "from torch.nn.init import zeros_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T22:53:39.121532Z",
     "iopub.status.busy": "2020-12-06T22:53:39.121532Z",
     "iopub.status.idle": "2020-12-06T22:53:39.125522Z",
     "shell.execute_reply": "2020-12-06T22:53:39.125522Z",
     "shell.execute_reply.started": "2020-12-06T22:53:39.121532Z"
    }
   },
   "outputs": [],
   "source": [
    "from bnet.bnet import BNET2d\n",
    "from bnet.activations import Swish, Mila, Mish, BentID, get_activation_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T22:53:39.212290Z",
     "iopub.status.busy": "2020-12-06T22:53:39.212290Z",
     "iopub.status.idle": "2020-12-06T22:53:39.218274Z",
     "shell.execute_reply": "2020-12-06T22:53:39.218274Z",
     "shell.execute_reply.started": "2020-12-06T22:53:39.212290Z"
    }
   },
   "outputs": [],
   "source": [
    "class rSoftMax(nn.Module):\n",
    "    def __init__(self, radix, cardinality):\n",
    "        super(rSoftMax, self).__init__()\n",
    "        self.radix = radix\n",
    "        self.cardinality = cardinality\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch = x.size(0)\n",
    "        if self.radix > 1:\n",
    "            x = x.view(batch, self.cardinality, self.radix, -1).transpose(1, 2)\n",
    "            x = F.softmax(x, dim=1)\n",
    "            x = x.reshape(batch, -1)\n",
    "        else: x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T22:53:39.333965Z",
     "iopub.status.busy": "2020-12-06T22:53:39.332967Z",
     "iopub.status.idle": "2020-12-06T22:53:39.346930Z",
     "shell.execute_reply": "2020-12-06T22:53:39.346930Z",
     "shell.execute_reply.started": "2020-12-06T22:53:39.332967Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Split Attention Conv2d\n",
    "\"\"\"\n",
    "class SplAtConv2d(nn.Module):\n",
    "    def __init__(self, ni, nf, ks, stride=(1,1), padding=(0,0), dilation=(1,1), groups=1, bias=True, radix=2, reduction_factor=4, norm='bn', act='relu', **kwargs):\n",
    "        super(SplAtConv2d, self).__init__()\n",
    "        padding = _pair(padding)\n",
    "        inter_channels = max(ni*radix//reduction_factor, 32)\n",
    "        self.norm = norm\n",
    "        self.radix = radix\n",
    "        self.cardinality = groups\n",
    "        self.channels = nf\n",
    "        if self.norm=='bn':\n",
    "            self.bn0 = nn.BatchNorm2d(nf*radix)\n",
    "            self.bn1 = nn.BatchNorm2d(inter_channels)\n",
    "            bias = False\n",
    "        elif self.norm=='bnet':\n",
    "            self.bn0 = BNET2d(nf*radix)\n",
    "            self.bn1 = BNET2d(inter_channels)\n",
    "        else: raise ValueError(f'norm is set to ({norm}), should be set to either bn or bnet')\n",
    "        self.conv = nn.Conv2d(ni, nf*radix, kernel_size=ks, stride=stride, padding=padding, dilation=dilation, groups=groups*radix, bias=bias, **kwargs)\n",
    "        self.act_fn = get_activation_(act)\n",
    "        self.conv_fc1 = nn.Conv2d(nf, inter_channels, 1, groups=self.cardinality)\n",
    "        self.conv_fc2 = nn.Conv2d(inter_channels, nf*radix, 1, groups=self.cardinality)\n",
    "        self.rsoftmax = rSoftMax(radix, groups)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        if self.use_bn: x = self.bn0(x)\n",
    "        x = self.act_fn(x)\n",
    "        \n",
    "        batch, rchannel = x.shape[:2]\n",
    "        \n",
    "        if self.radix > 1:\n",
    "            splitted = torch.split(x, rchannel//self.radix, dim=1)\n",
    "            gap = sum(splitted)\n",
    "        else: gap = x\n",
    "        gap = F.adaptive_avg_pool2d(gap, 1)\n",
    "        gap = self.conv_fc1(gap)\n",
    "        \n",
    "        if self.use_bn: gap = self.bn1(gap)\n",
    "        gap = self.act_fn(gap)\n",
    "        \n",
    "        atten = self.conv_fc2(gap)\n",
    "        atten = self.rsoftmax(atten).view(batch, -1, 1, 1)\n",
    "        \n",
    "        if self.radix > 1:\n",
    "            attens = torch.split(atten, rchannel//self.radix, dim=1)\n",
    "            out = sum([attn*split for (attn,split) in zip(attens, splitted)])\n",
    "        else: out = atten * x\n",
    "        \n",
    "        return out.contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T22:53:39.446664Z",
     "iopub.status.busy": "2020-12-06T22:53:39.446664Z",
     "iopub.status.idle": "2020-12-06T22:53:39.450653Z",
     "shell.execute_reply": "2020-12-06T22:53:39.450653Z",
     "shell.execute_reply.started": "2020-12-06T22:53:39.446664Z"
    }
   },
   "outputs": [],
   "source": [
    "class GlobalAvgPool2d(nn.Module):\n",
    "    \"\"\"Global average pooling over the input's spatial dimensions\"\"\"\n",
    "    def __init__(self): super(GlobalAvgPool2d, self).__init__()\n",
    "    def forward(self, x): return F.adaptive_avg_pool2d(x, 1).view(x.size(0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T22:53:39.565346Z",
     "iopub.status.busy": "2020-12-06T22:53:39.565346Z",
     "iopub.status.idle": "2020-12-06T22:53:39.570333Z",
     "shell.execute_reply": "2020-12-06T22:53:39.570333Z",
     "shell.execute_reply.started": "2020-12-06T22:53:39.565346Z"
    }
   },
   "outputs": [],
   "source": [
    "class Noop(nn.Module):\n",
    "    def __init__(self): super().__init__()\n",
    "    def forward(self, x): return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T22:53:39.681038Z",
     "iopub.status.busy": "2020-12-06T22:53:39.681038Z",
     "iopub.status.idle": "2020-12-06T22:53:39.694999Z",
     "shell.execute_reply": "2020-12-06T22:53:39.694999Z",
     "shell.execute_reply.started": "2020-12-06T22:53:39.681038Z"
    }
   },
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, radix=1, cardinality=1, bottleneck_width=64, avd=False, avd_first=False, dilation=1, is_first=False, norm='bn', last_gamma=False, act='relu'):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        group_width = int(planes * (bottleneck_width/64.)) * cardinality\n",
    "        self.conv1 = nn.Conv2d(inplanes, group_width, kernel_size=1, bias=False)\n",
    "        if norm=='bn': self.bn1 = nn.BatchNorm2d(group_width)\n",
    "        elif norm=='bnet': self.bn1 = BNET2d(group_width)\n",
    "        else: raise ValueError(f'norm is set to ({norm}), should be set to either bn or bnet')\n",
    "        self.radix = radix\n",
    "        self.avd = avd and (stride > 1 or is_first)\n",
    "        self.avd_first = avd_first\n",
    "        \n",
    "        if self.avd:\n",
    "            self.avd_layer = nn.AvgPool2d(3, stride, padding=1)\n",
    "            stride = 1\n",
    "            \n",
    "        if radix >= 1:\n",
    "            self.conv2 = SplAtConv2d(\n",
    "                group_width, group_width, ks=3,\n",
    "                stride=stride, padding=dilation,\n",
    "                dilation=dilation, groups=cardinality, bias=False,\n",
    "                radix=radix, norm=norm, act=act)\n",
    "        else:\n",
    "            self.conv2 = nn.Conv2d(\n",
    "                group_width, group_width, kernel_size=3,\n",
    "                stride=stride, padding=dilation, dilation=dilation,\n",
    "                groups=cardinality, bias=False)\n",
    "            if norm=='bn': self.bn2 = nn.BatchNorm2d(group_width)\n",
    "            elif norm=='bnet': self.bn2 = BNET2d(group_width)\n",
    "            else: raise ValueError(f'norm is set to ({norm}), should be set to either bn or bnet')\n",
    "            \n",
    "        self.conv3 = nn.Conv2d(\n",
    "            group_width, planes*4, kernel_size=1, bias=False)\n",
    "        if norm=='bn': self.bn3 = nn.BatchNorm2d(planes*4)\n",
    "        elif norm=='bnet': self.bn3 = BNET2d(planes*4)\n",
    "        else: raise ValueError(f'norm is set to ({norm}), should be set to either bn or bnet')\n",
    "                \n",
    "        if last_gamma and norm=='bn': zeros_(self.bn3.weight)\n",
    "        \n",
    "        self.act = get_activation_(act)\n",
    "        self.downsample = downsample\n",
    "        self.dilation = dilation\n",
    "        self.stride = stride\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.act(out)\n",
    "        if self.avd and self.avd_first: out = self.avd_layer(out)\n",
    "            \n",
    "        out = self.conv2(out)\n",
    "        if self.radix==0:\n",
    "            out = self.bn2(out)\n",
    "            out = self.act(out)\n",
    "        if self.avd and not self.avd_first: out = self.avd_layer(out)\n",
    "            \n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        if self.downsample is not None: residual = self.downsample(x)\n",
    "        out += residual\n",
    "        out = self.act(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T22:53:39.784760Z",
     "iopub.status.busy": "2020-12-06T22:53:39.784760Z",
     "iopub.status.idle": "2020-12-06T22:53:39.796728Z",
     "shell.execute_reply": "2020-12-06T22:53:39.796728Z",
     "shell.execute_reply.started": "2020-12-06T22:53:39.784760Z"
    }
   },
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, radix=1, cardinality=1, bottleneck_width=64, avd=False, avd_first=False, dilation=1, is_first=False, norm='bn', last_gamma=False, act='relu'):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        group_width = int(planes * (bottleneck_width/64.)) * cardinality\n",
    "        self.conv1 = nn.Conv2d(inplanes, group_width, kernel_size=3, bias=False, stride=stride, padding=dilation, dilation=dilation)\n",
    "        if norm=='bn': self.bn1 = nn.BatchNorm2d(group_width)\n",
    "        elif norm=='bnet': self.bn1 = BNET2d(group_width)\n",
    "        else: raise ValueError(f'norm is set to ({norm}), should be set to either bn or bnet')\n",
    "        self.radix = radix\n",
    "        self.avd = avd and (stride > 1 or is_first)\n",
    "        if self.avd: stride = 1\n",
    "            \n",
    "        if radix >= 1:\n",
    "            self.conv2 = SplAtConv2d(\n",
    "                group_width, group_width, ks=3,\n",
    "                stride=stride, padding=dilation,\n",
    "                dilation=dilation, groups=cardinality, bias=False,\n",
    "                radix=radix, norm=norm, act=act)\n",
    "        else:\n",
    "            self.conv2 = nn.Conv2d(\n",
    "                group_width, group_width, kernel_size=3,\n",
    "                stride=stride, padding=dilation, dilation=dilation,\n",
    "                groups=cardinality, bias=False)\n",
    "            if norm=='bn': self.bn2 = nn.BatchNorm2d(group_width)\n",
    "            elif norm=='bnet': self.bn2 = BNET2d(group_width)\n",
    "            else: raise ValueError(f'norm is set to ({norm}), should be set to either bn or bnet')\n",
    "        \n",
    "        if last_gamma and norm=='bn': zeros_(self.bn2.weight)\n",
    "        \n",
    "        self.act = get_activation_(act)\n",
    "        self.downsample = downsample\n",
    "        self.dilation = dilation\n",
    "        self.stride = stride\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.act(out)\n",
    "            \n",
    "        out = self.conv2(out)\n",
    "        if self.radix==0:\n",
    "            out = self.bn2(out)\n",
    "            \n",
    "        if self.downsample is not None: residual = self.downsample(x)\n",
    "        out += residual\n",
    "        out = self.act(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T22:53:39.896462Z",
     "iopub.status.busy": "2020-12-06T22:53:39.895464Z",
     "iopub.status.idle": "2020-12-06T22:53:39.901448Z",
     "shell.execute_reply": "2020-12-06T22:53:39.901448Z",
     "shell.execute_reply.started": "2020-12-06T22:53:39.896462Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_norm_(inplanes, norm_='bn', **kwargs):\n",
    "    norm_type_ = nn.ModuleDict([\n",
    "        ['bn', nn.BatchNorm2d(inplanes, **kwargs)],\n",
    "        ['gn', nn.GroupNorm(1, inplanes, **kwargs)],\n",
    "        ['bnet', BNET2d(width=inplanes, **kwargs)]\n",
    "    ])\n",
    "    return norm_type_[norm_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T22:53:40.011156Z",
     "iopub.status.busy": "2020-12-06T22:53:40.011156Z",
     "iopub.status.idle": "2020-12-06T22:53:40.039080Z",
     "shell.execute_reply": "2020-12-06T22:53:40.039080Z",
     "shell.execute_reply.started": "2020-12-06T22:53:40.011156Z"
    }
   },
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, radix=1, groups=1, bottleneck_width=64, c_in=3, num_classes=1000, dilated=False, dilation=1, deep_stem=False, stem_width=64, avg_down=False, avd=False, avd_first=False, final_drop=0.0, last_gamma=False, norm='bn', act='relu'):\n",
    "        self.cardinality = groups\n",
    "        self.bottleneck_width = bottleneck_width\n",
    "        self.inplanes = stem_width*2 if deep_stem else 64\n",
    "        self.avg_down = avg_down\n",
    "        self.last_gamma = last_gamma\n",
    "        self.norm = norm\n",
    "        self.radix = radix\n",
    "        self.avd = avd\n",
    "        self.avd_first = avd_first\n",
    "        \n",
    "        super(ResNet, self).__init__()\n",
    "        self.act_fn = get_activation_(act)\n",
    "        conv_layer = nn.Conv2d\n",
    "        conv_kwargs = {}\n",
    "        if deep_stem:\n",
    "            self.conv1 = nn.Sequential(\n",
    "                conv_layer(c_in, stem_width, kernel_size=3, stride=2, padding=1, bias=False, **conv_kwargs),\n",
    "                create_norm_(stem_width, norm_=norm), self.act_fn,\n",
    "                conv_layer(stem_width, stem_width, kernel_size=3, stride=1, padding=1, bias=False, **conv_kwargs),\n",
    "                create_norm_(stem_width, norm_=norm), self.act_fn,\n",
    "                conv_layer(stem_width, stem_width*2, kernel_size=3, stride=1, padding=1, bias=False, **conv_kwargs))\n",
    "        else: self.conv1 = conv_layer(c_in, 64, kernel_size=7, stride=3, padding=3, bias=False, **conv_kwargs)\n",
    "        self.bn1 = create_norm_(self.inplanes, norm_=norm)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0], norm=norm, is_first=False, act=act)\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2, norm=norm, act=act)\n",
    "        \n",
    "        if dilated or dilation==4:\n",
    "            self.layer3 = self._make_layer(block, 256, layers[2], stride=1, dilation=2, norm=norm, act=act)\n",
    "            self.layer4 = self._make_layer(block, 512, layers[3], stride=1, dilation=4, norm=norm, act=act)\n",
    "        elif dilation==2:\n",
    "            self.layer3 = self._make_layer(block, 256, layers[2], stride=2, dilation=1, norm=norm, act=act)\n",
    "            self.layer4 = self._make_layer(block, 512, layers[3], stride=1, dilation=2, norm=norm, act=act)\n",
    "        else:\n",
    "            self.layer3 = self._make_layer(block, 256, layers[2], stride=2, norm=norm, act=act)\n",
    "            self.layer4 = self._make_layer(block, 512, layers[3], stride=2, norm=norm, act=act)\n",
    "        \n",
    "        self.avgpool = GlobalAvgPool2d()\n",
    "        self.drop = nn.Dropout(final_drop) if final_drop > 0.0 else None\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. /n))\n",
    "            elif isinstance(m, nn.BatchNorm2d) and norm=='bn':\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "                \n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilation=1, norm='bn', is_first=True, act='relu'):\n",
    "        downsample = None\n",
    "        \n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            down_layers = []\n",
    "            if self.avg_down:\n",
    "                if dilation == 1: down_layers.append(nn.AvgPool2d(kernel_size=stride, stride=stride, ceil_mode=True, count_include_pad=False))\n",
    "                else: down_layers.append(nn.AvgPool2d(kernel_size=1, stride=1, ceil_mode=True, count_include_pad=False))\n",
    "                down_layers.append(nn.Conv2d(self.inplanes, planes * block.expansion, kernel_size=1, stride=1, bias=False))\n",
    "            else: down_layers.append(nn.Conv2d(self.inplanes, planes * block.expansion, kernel_size=1, stride=stride, bias=False))\n",
    "            down_layers.append(create_norm_(planes*block.expansion, norm_=norm))\n",
    "            downsample = nn.Sequential(*down_layers)\n",
    "        \n",
    "        layers = []\n",
    "        if dilation == 1 or dilation == 2:\n",
    "            layers.append(block(self.inplanes, planes, stride, downsample=downsample,\n",
    "                                radix=self.radix, cardinality=self.cardinality, bottleneck_width=self.bottleneck_width,\n",
    "                                avd=self.avd, avd_first=self.avd_first, dilation=1, is_first=is_first, norm=norm,\n",
    "                                last_gamma=self.last_gamma, act=act))\n",
    "        elif dilation==4:\n",
    "            layers.append(block(self.inplanes, planes, stride, downsample=downsample,\n",
    "                                radix=self.radix, cardinality=self.cardinality, bottleneck_width=self.bottleneck_width,\n",
    "                                avd=self.avd, avd_first=self.avd_first, dilation=2, is_first=is_first, norm=norm,\n",
    "                                last_gamma=self.last_gamma, act=act))\n",
    "        else: raise RuntimeError(\"=> unknown dilation size: {}\".format(dilation))\n",
    "        \n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes,\n",
    "                                radix=self.radix, cardinality=self.cardinality,\n",
    "                                bottleneck_width=self.bottleneck_width, avd=self.avd,\n",
    "                                avd_first=self.avd_first, dilation=dilation, norm=norm,\n",
    "                                last_gamma=self.last_gamma, act=act))\n",
    "            \n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        if self.bn1: x = self.bn1(x)\n",
    "        x = self.act_fn(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        if self.drop: x = self.drop(x)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T22:53:40.121859Z",
     "iopub.status.busy": "2020-12-06T22:53:40.121859Z",
     "iopub.status.idle": "2020-12-06T22:53:40.126846Z",
     "shell.execute_reply": "2020-12-06T22:53:40.126846Z",
     "shell.execute_reply.started": "2020-12-06T22:53:40.121859Z"
    }
   },
   "outputs": [],
   "source": [
    "def mininest_ba(c_in=3, num_classes=1000, act='relu', **kwargs):\n",
    "    \"\"\"\n",
    "    uses BasicBlock\n",
    "    \"\"\"\n",
    "    layers = [1, 1, 1, 1]\n",
    "    model = ResNet(BasicBlock, layers,\n",
    "                   radix=2, groups=1, bottleneck_width=64,\n",
    "                   deep_stem=True, stem_width=32, avg_down=True,\n",
    "                   avd=True, avd_first=False, c_in=c_in, num_classes=num_classes, act=act, **kwargs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T22:53:40.224585Z",
     "iopub.status.busy": "2020-12-06T22:53:40.224585Z",
     "iopub.status.idle": "2020-12-06T22:53:40.229572Z",
     "shell.execute_reply": "2020-12-06T22:53:40.229572Z",
     "shell.execute_reply.started": "2020-12-06T22:53:40.224585Z"
    }
   },
   "outputs": [],
   "source": [
    "def mininest_bn(c_in=3, num_classes=1000, act='relu', **kwargs):\n",
    "    \"\"\"\n",
    "    uses Bottleneck Block\n",
    "    \"\"\"\n",
    "    layers = [1, 1, 1, 1]\n",
    "    model = ResNet(Bottleneck, layers,\n",
    "                   radix=2, groups=1, bottleneck_width=64,\n",
    "                   deep_stem=True, stem_width=32, avg_down=True,\n",
    "                   avd=True, avd_first=False, c_in=c_in, num_classes=num_classes, act=act, **kwargs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-07T00:00:28.292228Z",
     "iopub.status.busy": "2020-12-07T00:00:28.292228Z",
     "iopub.status.idle": "2020-12-07T00:00:28.300207Z",
     "shell.execute_reply": "2020-12-07T00:00:28.300207Z",
     "shell.execute_reply.started": "2020-12-07T00:00:28.292228Z"
    }
   },
   "outputs": [],
   "source": [
    "from bnet.models import mininest_ba, mininest_bn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-07T00:00:42.537228Z",
     "iopub.status.busy": "2020-12-07T00:00:42.537228Z",
     "iopub.status.idle": "2020-12-07T00:00:42.673891Z",
     "shell.execute_reply": "2020-12-07T00:00:42.673891Z",
     "shell.execute_reply.started": "2020-12-07T00:00:42.537228Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (act_fn): ReLU(inplace=True)\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): BNET2d(\n",
       "      32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True\n",
       "      (bnconv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
       "    )\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (4): BNET2d(\n",
       "      32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True\n",
       "      (bnconv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
       "    )\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  )\n",
       "  (bn1): BNET2d(\n",
       "    64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True\n",
       "    (bnconv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
       "  )\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BNET2d(\n",
       "        64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True\n",
       "        (bnconv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
       "      )\n",
       "      (conv2): SplAtConv2d(\n",
       "        (bn0): BNET2d(\n",
       "          128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True\n",
       "          (bnconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "        )\n",
       "        (bn1): BNET2d(\n",
       "          32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True\n",
       "          (bnconv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
       "        )\n",
       "        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (act_fn): ReLU(inplace=True)\n",
       "        (conv_fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (conv_fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): rSoftMax()\n",
       "      )\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BNET2d(\n",
       "        256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True\n",
       "        (bnconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "      )\n",
       "      (act): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
       "        (1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): BNET2d(\n",
       "          256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True\n",
       "          (bnconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BNET2d(\n",
       "        128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True\n",
       "        (bnconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "      )\n",
       "      (avd_layer): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
       "      (conv2): SplAtConv2d(\n",
       "        (bn0): BNET2d(\n",
       "          256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True\n",
       "          (bnconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "        )\n",
       "        (bn1): BNET2d(\n",
       "          64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True\n",
       "          (bnconv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
       "        )\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (act_fn): ReLU(inplace=True)\n",
       "        (conv_fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (conv_fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): rSoftMax()\n",
       "      )\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BNET2d(\n",
       "        512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True\n",
       "        (bnconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "      )\n",
       "      (act): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        (1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): BNET2d(\n",
       "          512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True\n",
       "          (bnconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BNET2d(\n",
       "        256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True\n",
       "        (bnconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "      )\n",
       "      (avd_layer): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
       "      (conv2): SplAtConv2d(\n",
       "        (bn0): BNET2d(\n",
       "          512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True\n",
       "          (bnconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "        )\n",
       "        (bn1): BNET2d(\n",
       "          128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True\n",
       "          (bnconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "        )\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (act_fn): ReLU(inplace=True)\n",
       "        (conv_fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (conv_fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): rSoftMax()\n",
       "      )\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BNET2d(\n",
       "        1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True\n",
       "        (bnconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "      )\n",
       "      (act): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        (1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): BNET2d(\n",
       "          1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True\n",
       "          (bnconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BNET2d(\n",
       "        512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True\n",
       "        (bnconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "      )\n",
       "      (avd_layer): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
       "      (conv2): SplAtConv2d(\n",
       "        (bn0): BNET2d(\n",
       "          1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True\n",
       "          (bnconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "        )\n",
       "        (bn1): BNET2d(\n",
       "          256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True\n",
       "          (bnconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "        )\n",
       "        (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (act_fn): ReLU(inplace=True)\n",
       "        (conv_fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (conv_fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): rSoftMax()\n",
       "      )\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BNET2d(\n",
       "        2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True\n",
       "        (bnconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n",
       "      )\n",
       "      (act): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        (1): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): BNET2d(\n",
       "          2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True\n",
       "          (bnconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (avgpool): GlobalAvgPool2d()\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mininest_bn(norm='bnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
